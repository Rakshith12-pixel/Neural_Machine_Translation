{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakshith12-pixel/Neural_Machine_Translation/blob/main/dl4cvnlp_nmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk_vKh4YEfhl"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms8SJA8jELck"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is the baseline model we will be comparing against**"
      ],
      "metadata": {
        "id": "bhk0GH7It4Vg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW-WstYmH-4I"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim    # Dimension of embedding. 4 in the dummy example\n",
        "        self.dense_dim = dense_dim    # No. of neurons in dense layer\n",
        "        self.num_heads = num_heads    # No. of heads for MultiHead Attention layer\n",
        "        self.attention = layers.MultiHeadAttention(   # MultiHead Attention layer -\n",
        "            num_heads=num_heads, key_dim=embed_dim)   # see coloured pic above\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]    # encoders are stacked on top of the other.\n",
        "        )                                 # So output dimension is also embed_dim\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    # Call function based on figure above\n",
        "    def call(self, inputs, mask_=None):\n",
        "        if mask_ is not None:\n",
        "            mask = mask[:, tf.newaxis, :]   # Will discuss in next tutorial\n",
        "            print(f\"**test: mask in not None. mask = {mask_}\")\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask_)  # Query: inputs, Value: inputs, Keys: Same as Values by default\n",
        "                                                  # Q: Can you see how this is self attention?\n",
        "        proj_input = self.layernorm_1(inputs + attention_output) # LayerNormalization; + Recall cat picture\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)  # LayerNormalization + Residual connection\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCAWpi5zGUlx"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        # input_dim = (token) vocabulary size,  output_dim = embedding size\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.token_embeddings = layers.Embedding(       # Q: what is input_dim and output_dim?\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(    # Q: Why input_dim = seq_length?\n",
        "            input_dim=sequence_length, output_dim=output_dim)   # Q: What is the vocab for this Embedding layer\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):   # inputs will be a batch of sequences (batch, seq_len)\n",
        "\n",
        "        length = tf.shape(inputs)[-1]     # lenght will just be sequence length\n",
        "        positions = tf.range(start=0, limit=length, delta=1) # indices for input to positional embedding\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions     # ADD the embeddings\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):  # makes this layer a mask-generating layer\n",
        "        return tf.math.not_equal(inputs, 0)     #mask will get propagated to the next layer.\n",
        "\n",
        "    # When using custom layers, this enables the layer to be reinstantiated from its config dict,\n",
        "    # which is useful during model saving and loading.\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T92X85GUFCLn"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        # Define the layers. Let's point them out in the diagram\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        # Now we have 2 MultiHead Attention layers - one for ___ attention and one for ____ attention\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True #ensures that the layer will propagate its input mask to its outputs;\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1])) # sequence_length == input_shape[1]\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "              tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask_=None): # two inputs: decoder i/p and encoder o/p\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        attention_output_1 = self.attention_1(    # Q: What kind of attention?\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask) # Q: What will the causal_mask do?\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(  # Q: Is this self attention?\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,    # Key and Value coming from encoder hence this is cross attention\n",
        "            key=encoder_outputs,\n",
        "            # attention_mask=padding_mask,\n",
        "        )\n",
        "\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ltu1dmtHoyV",
        "outputId": "605e6711-81b9-4628-92d7-bab56e9ad561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            5125120   ['english[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Po  (None, None, 256)            5125120   ['spanish[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Tra  (None, None, 256)            3155456   ['positional_embedding_1[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_2[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 256)            0         ['transformer_decoder[0][0]'] \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, None, 20000)          5140000   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23805216 (90.81 MB)\n",
            "Trainable params: 23805216 (90.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# English to spanish translation\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "sequence_length = 20\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs) # Q: First arg acts like a ___ for pos embedding layer\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) #Q: What are these arguments?\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs,mask_=None) # Q: What are the call arguments in the picture?\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs) # Note that there are two input layers\n",
        "transformer.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605e6711-81b9-4628-92d7-bab56e9ad561",
        "id": "BP-eYSdKkT2j"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            5125120   ['english[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Po  (None, None, 256)            5125120   ['spanish[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Tra  (None, None, 256)            3155456   ['positional_embedding_1[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_2[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 256)            0         ['transformer_decoder[0][0]'] \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, None, 20000)          5140000   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23805216 (90.81 MB)\n",
            "Trainable params: 23805216 (90.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# English to spanish translation\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "sequence_length = 20\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs) # Q: First arg acts like a ___ for pos embedding layer\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) #Q: What are these arguments?\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs,mask_=None) # Q: What are the call arguments in the picture?\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs) # Note that there are two input layers\n",
        "transformer.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0Y2NmDV7lF6"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr3nOQKCEOCe"
      },
      "source": [
        "Download the data for english to spanish translation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjxZZr-KujpN",
        "outputId": "0067c6a1-471a-4bc0-89a2-4f51c1f0ff41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-26 12:15:49--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.145.207, 74.125.128.207, 74.125.143.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.145.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "spa-eng.zip         100%[===================>]   2.52M  3.77MB/s    in 0.7s    \n",
            "\n",
            "2023-11-26 12:15:49 (3.77 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -q spa-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxaC6lh95Ox2",
        "outputId": "eda4c979-0e40-4768-cbbb-e7870bcdaea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can't view Flash content on an iPad. However, you can easily email yourself the URLs of these web pages and view that content on your regular computer when you get home.\tNo puedes ver contenido en Flash en un iPad. Sin embargo, puedes fácilmente enviarte por correo electrónico las URL's de esas páginas web y ver el contenido en tu computadora cuando llegas a casa.\n",
            "A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\tUn error que cometen a menudo los jóvenes es el de comenzar a aprender demasiadas lenguas al mismo tiempo, porque subestiman sus dificultades y sobrestiman sus propias capacidades para aprenderlas.\n",
            "No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\tNo importa cuánto insistas en convencer a la gente de que el chocolate es vainilla, seguirá siendo chocolate, aunque puede que te convenzas a ti mismo y a algunos otros de que es vainilla.\n",
            "In 1969, Roger Miller recorded a song called \"You Don't Want My Love.\" Today, this song is better known as \"In the Summer Time.\" It's the first song he wrote and sang that became popular.\tEn 1969, Roger Miller grabó una canción llamada \"Tú no quieres mi amor\". Hoy, esta canción es más conocida como \"En el verano\". Es la primera canción que escribió y cantó que se convirtió popular.\n",
            "A child who is a native speaker usually knows many things about his or her language that a non-native speaker who has been studying for years still does not know and perhaps will never know.\tUn niño que es hablante nativo normalmente sabe muchas cosas acerca de su lengua que un hablante no nativo que lo haya estado estudiando durante muchos años no sabe todavía y que quizá no sabrá nunca.\n",
            "There are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.\tHay cuatro causas principales de muertes relacionadas con el alcohol. Lesión por un accidente automovilístico o violencia es una. Enfermedades como cirrosis del hígado, cáncer, enfermedades del corazón y del sistema circulatorio son las otras.\n",
            "There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college education.\tHay madres y padres que se quedan despiertos después de que sus hijos se hayan dormido y se preguntan cómo conseguir pagar la hipoteca o las facturas del médico, o cómo ahorrar el suficiente dinero para la educación universitaria de sus hijos.\n",
            "A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\tUna huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque están preocupados acerca del cambio climático.\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tComo suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a la siguiente página encontrada por Google y espero encontrar algo menos irritante.\n",
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\tSi quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n"
          ]
        }
      ],
      "source": [
        "!tail spa-eng/spa.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxxtnbv9D2-u",
        "outputId": "2664cf29-c064-407c-b6c8-8607436a3c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Tom is just like you.', '[start] Tom es tal y como tú. [end]')\n",
            "no. of pairs: 118964\n"
          ]
        }
      ],
      "source": [
        "# pre-processing. Separating input and output sequences\n",
        "text_file = \"spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    english, spanish = line.split(\"\\t\")\n",
        "    spanish = \"[start] \" + spanish + \" [end]\" #why isnt same done for english??\n",
        "    text_pairs.append((english, spanish))\n",
        "\n",
        "import random\n",
        "print(random.choice(text_pairs))\n",
        "print(f\"no. of pairs: {len(text_pairs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcybUiQTD3Az"
      },
      "outputs": [],
      "source": [
        "#splitting data\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pimrC_sEb-I"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj9HjcGE7h4N",
        "outputId": "30e480dc-4699-4634-8de7-cd4d1b87a624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "print(string.punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBc6EItWD3C3"
      },
      "outputs": [],
      "source": [
        "# Vectorizing the English and Spanish text pairs\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Define which characters to strip out for spanish data- [, ], ¿\n",
        "strip_chars = string.punctuation + \"¿\"  # strip out stadard punctuations + extra one in spanish\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "# strio_chars = !\"#$%&'()*+,-./:;<=>?@\\\\^_`{|}~¿\n",
        "\n",
        "# Custom standardization function for spanish\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(    # Replace elements of input matching regex pattern with rewrite.\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcrueo70ljha"
      },
      "outputs": [],
      "source": [
        "#splitting data\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8pvgWeYljhr"
      },
      "outputs": [],
      "source": [
        "# Vectorizing the English and Spanish text pairs\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Define which characters to strip out for spanish data- [, ], ¿\n",
        "strip_chars = string.punctuation + \"¿\"  # strip out stadard punctuations + extra one in spanish\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "# strio_chars = !\"#$%&'()*+,-./:;<=>?@\\\\^_`{|}~¿\n",
        "\n",
        "# Custom standardization function for spanish\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(    # Replace elements of input matching regex pattern with rewrite.\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvGBDNOmEkMb"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HndSHekBRwZ",
        "outputId": "ddf93d4a-ffdf-449c-efb2-2f66c047a115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original seq\n",
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
            "dec_in\n",
            "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int32)\n",
            "dec_out\n",
            "tf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "seq = tf.range(10)\n",
        "dec_in = seq[:-1]\n",
        "dec_out = seq[1:]\n",
        "\n",
        "print(\"original seq\")\n",
        "print(seq)\n",
        "\n",
        "print(\"dec_in\")\n",
        "print(dec_in)\n",
        "\n",
        "print(\"dec_out\")\n",
        "print(dec_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMicSLvGD3E_"
      },
      "outputs": [],
      "source": [
        "# Preparing datasets for the translation task\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# returns tuple- ()\n",
        "def format_dataset(eng, spa):\n",
        "    # Q: What are eng and spa pre and post re-assignment\n",
        "    eng = source_vectorization(eng)\n",
        "    spa = target_vectorization(spa)\n",
        "    return ({\n",
        "        \"english\": eng,           # encoder nput\n",
        "        \"spanish\": spa[:, :-1],    # decoder input Q: what is the first axis?\n",
        "    }, spa[:, 1:])                  # decoder ouput\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache() #Use in-memory caching to speed up preprocessing.\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A2wVFs8Epoy",
        "outputId": "a723fe4e-39d3-4728-96ec-601f3c08d6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['spanish'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n",
            "tf.Tensor(\n",
            "[2767    6   51   44   81    6   41    4   32  630   65   20  154    3\n",
            "    0    0    0    0    0    0], shape=(20,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[  3  75 110  62 109  58 688 148 106   0   0   0   0   0   0   0   0   0\n",
            "   0   0], shape=(20,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")\n",
        "    print(targets[3])\n",
        "    print(inputs['english'][3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54BdC0gg7pQS"
      },
      "source": [
        "## Traning and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XjE0Bv-ybZr",
        "outputId": "42a2c6b2-1e1a-475b-e04a-4b6cc6134d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformer\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "fa8C9cTayYDy",
        "outputId": "32b61534-f7c4-438f-d129-bdd2911e1325"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1c49d42d5583>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wd0SMFiZQJz",
        "outputId": "b6cceb8c-8fbd-4546-8964-c9e0ad7bcbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1302/1302 [==============================] - 133s 92ms/step - loss: 4.0376 - accuracy: 0.4115 - val_loss: 2.7648 - val_accuracy: 0.5716\n",
            "Epoch 2/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 2.6468 - accuracy: 0.5960 - val_loss: 2.2234 - val_accuracy: 0.6439\n",
            "Epoch 3/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 2.2522 - accuracy: 0.6494 - val_loss: 2.0483 - val_accuracy: 0.6717\n",
            "Epoch 4/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 2.0551 - accuracy: 0.6773 - val_loss: 1.9875 - val_accuracy: 0.6844\n",
            "Epoch 5/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.9374 - accuracy: 0.6945 - val_loss: 1.9939 - val_accuracy: 0.6859\n",
            "Epoch 6/30\n",
            "1302/1302 [==============================] - 111s 85ms/step - loss: 1.8575 - accuracy: 0.7078 - val_loss: 1.9705 - val_accuracy: 0.6925\n",
            "Epoch 7/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.8041 - accuracy: 0.7176 - val_loss: 1.9876 - val_accuracy: 0.6926\n",
            "Epoch 8/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.7643 - accuracy: 0.7254 - val_loss: 2.0143 - val_accuracy: 0.6948\n",
            "Epoch 9/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.7337 - accuracy: 0.7313 - val_loss: 2.0249 - val_accuracy: 0.6966\n",
            "Epoch 10/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.7068 - accuracy: 0.7372 - val_loss: 2.0250 - val_accuracy: 0.6961\n",
            "Epoch 11/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.6794 - accuracy: 0.7416 - val_loss: 2.0601 - val_accuracy: 0.6972\n",
            "Epoch 12/30\n",
            "1302/1302 [==============================] - 118s 91ms/step - loss: 1.6521 - accuracy: 0.7477 - val_loss: 2.0921 - val_accuracy: 0.6961\n",
            "Epoch 13/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.6318 - accuracy: 0.7514 - val_loss: 2.1017 - val_accuracy: 0.6967\n",
            "Epoch 14/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.6116 - accuracy: 0.7555 - val_loss: 2.1037 - val_accuracy: 0.6973\n",
            "Epoch 15/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5932 - accuracy: 0.7588 - val_loss: 2.1373 - val_accuracy: 0.6951\n",
            "Epoch 16/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5724 - accuracy: 0.7631 - val_loss: 2.1424 - val_accuracy: 0.6964\n",
            "Epoch 17/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5569 - accuracy: 0.7662 - val_loss: 2.1714 - val_accuracy: 0.6975\n",
            "Epoch 18/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5409 - accuracy: 0.7693 - val_loss: 2.2033 - val_accuracy: 0.6940\n",
            "Epoch 19/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5238 - accuracy: 0.7720 - val_loss: 2.1923 - val_accuracy: 0.6967\n",
            "Epoch 20/30\n",
            "1302/1302 [==============================] - 118s 91ms/step - loss: 1.5107 - accuracy: 0.7749 - val_loss: 2.2656 - val_accuracy: 0.6930\n",
            "Epoch 21/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.4955 - accuracy: 0.7775 - val_loss: 2.2333 - val_accuracy: 0.6944\n",
            "Epoch 22/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4824 - accuracy: 0.7801 - val_loss: 2.2791 - val_accuracy: 0.6946\n",
            "Epoch 23/30\n",
            "1302/1302 [==============================] - 118s 91ms/step - loss: 1.4698 - accuracy: 0.7824 - val_loss: 2.2821 - val_accuracy: 0.6939\n",
            "Epoch 24/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.4590 - accuracy: 0.7846 - val_loss: 2.3207 - val_accuracy: 0.6918\n",
            "Epoch 25/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4503 - accuracy: 0.7862 - val_loss: 2.3206 - val_accuracy: 0.6934\n",
            "Epoch 26/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4361 - accuracy: 0.7888 - val_loss: 2.3620 - val_accuracy: 0.6941\n",
            "Epoch 27/30\n",
            "1302/1302 [==============================] - 118s 91ms/step - loss: 1.4265 - accuracy: 0.7907 - val_loss: 2.3400 - val_accuracy: 0.6960\n",
            "Epoch 28/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4171 - accuracy: 0.7931 - val_loss: 2.3506 - val_accuracy: 0.6941\n",
            "Epoch 29/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4114 - accuracy: 0.7937 - val_loss: 2.4329 - val_accuracy: 0.6918\n",
            "Epoch 30/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.4006 - accuracy: 0.7958 - val_loss: 2.4055 - val_accuracy: 0.6914\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7df3c36e6020>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]) # other metrics like Bleu....\n",
        "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ije_bIxsnGc"
      },
      "source": [
        "Note that both the Trans- formerEncoder and the TransformerDecoder are shape-invariant, so you could be stacking many of them to create a more powerful encoder or decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying different architectures**"
      ],
      "metadata": {
        "id": "VVCgLy_psphZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model having 3 encoder and decoder layers, to test how the depth of the network affects accuracy"
      ],
      "metadata": {
        "id": "hUFHnhkk2wxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "sequence_length = 20\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "\n",
        "# Add 3 Encoder Layers\n",
        "for _ in range(3):\n",
        "    x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "encoder_outputs = x  # Output of the final encoder layer\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "\n",
        "# Add 3 Decoder Layers\n",
        "for _ in range(3):\n",
        "    x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs, mask_=None)\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "# Model\n",
        "transformer_2 = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "transformer_2.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJP1z4li0_MA",
        "outputId": "f8853637-6180-498d-ef2a-dab1e5f5f83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding (Posi  (None, None, 256)            3845120   ['english[0][0]']             \n",
            " tionalEmbedding)                                                                                 \n",
            "                                                                                                  \n",
            " transformer_encoder (Trans  (None, None, 256)            3155456   ['positional_embedding[0][0]']\n",
            " formerEncoder)                                                                                   \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Tra  (None, None, 256)            3155456   ['transformer_encoder[0][0]'] \n",
            " nsformerEncoder)                                                                                 \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            3845120   ['spanish[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_2 (Tra  (None, None, 256)            3155456   ['transformer_encoder_1[0][0]'\n",
            " nsformerEncoder)                                                   ]                             \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_1[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " transformer_decoder_1 (Tra  (None, None, 256)            5259520   ['transformer_decoder[0][0]', \n",
            " nsformerDecoder)                                                    'transformer_encoder_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " transformer_decoder_2 (Tra  (None, None, 256)            5259520   ['transformer_decoder_1[0][0]'\n",
            " nsformerDecoder)                                                   , 'transformer_encoder_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, None, 256)            0         ['transformer_decoder_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, None, 15000)          3855000   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 36790168 (140.34 MB)\n",
            "Trainable params: 36790168 (140.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_2.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]) # other metrics like Bleu....\n"
      ],
      "metadata": {
        "id": "cRjz7JulrPDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_2.fit(train_ds, epochs=30, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF0jdhTB2Xev",
        "outputId": "03d298e6-f34e-47bb-beb3-5163a1264dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1302/1302 [==============================] - 215s 152ms/step - loss: 4.7452 - accuracy: 0.2961 - val_loss: 4.1894 - val_accuracy: 0.3449\n",
            "Epoch 2/30\n",
            "1302/1302 [==============================] - 186s 142ms/step - loss: 4.4947 - accuracy: 0.3128 - val_loss: 4.0818 - val_accuracy: 0.3549\n",
            "Epoch 3/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 4.1411 - accuracy: 0.3526 - val_loss: 4.0214 - val_accuracy: 0.3552\n",
            "Epoch 4/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 4.0533 - accuracy: 0.3644 - val_loss: 3.9224 - val_accuracy: 0.3707\n",
            "Epoch 5/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.9848 - accuracy: 0.3740 - val_loss: 3.9003 - val_accuracy: 0.3747\n",
            "Epoch 6/30\n",
            "1302/1302 [==============================] - 189s 145ms/step - loss: 3.9260 - accuracy: 0.3822 - val_loss: 3.8845 - val_accuracy: 0.3789\n",
            "Epoch 7/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.8814 - accuracy: 0.3883 - val_loss: 3.8895 - val_accuracy: 0.3825\n",
            "Epoch 8/30\n",
            "1302/1302 [==============================] - 186s 143ms/step - loss: 3.8414 - accuracy: 0.3952 - val_loss: 3.8935 - val_accuracy: 0.3793\n",
            "Epoch 9/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.8076 - accuracy: 0.4005 - val_loss: 3.8993 - val_accuracy: 0.3836\n",
            "Epoch 10/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.7780 - accuracy: 0.4050 - val_loss: 3.9004 - val_accuracy: 0.3838\n",
            "Epoch 11/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.7469 - accuracy: 0.4105 - val_loss: 3.9366 - val_accuracy: 0.3840\n",
            "Epoch 12/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.7184 - accuracy: 0.4153 - val_loss: 3.9289 - val_accuracy: 0.3817\n",
            "Epoch 13/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.6929 - accuracy: 0.4191 - val_loss: 3.9703 - val_accuracy: 0.3840\n",
            "Epoch 14/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.6674 - accuracy: 0.4234 - val_loss: 3.9578 - val_accuracy: 0.3841\n",
            "Epoch 15/30\n",
            "1302/1302 [==============================] - 188s 145ms/step - loss: 3.6429 - accuracy: 0.4270 - val_loss: 3.9715 - val_accuracy: 0.3836\n",
            "Epoch 16/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.6216 - accuracy: 0.4306 - val_loss: 4.0003 - val_accuracy: 0.3786\n",
            "Epoch 17/30\n",
            "1302/1302 [==============================] - 189s 145ms/step - loss: 3.6027 - accuracy: 0.4336 - val_loss: 3.9841 - val_accuracy: 0.3856\n",
            "Epoch 18/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.5800 - accuracy: 0.4377 - val_loss: 4.0211 - val_accuracy: 0.3845\n",
            "Epoch 19/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.5633 - accuracy: 0.4405 - val_loss: 4.0343 - val_accuracy: 0.3802\n",
            "Epoch 20/30\n",
            "1302/1302 [==============================] - 189s 145ms/step - loss: 3.5439 - accuracy: 0.4438 - val_loss: 4.0524 - val_accuracy: 0.3829\n",
            "Epoch 21/30\n",
            "1302/1302 [==============================] - 186s 142ms/step - loss: 3.5262 - accuracy: 0.4473 - val_loss: 4.0576 - val_accuracy: 0.3824\n",
            "Epoch 22/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.5094 - accuracy: 0.4502 - val_loss: 4.0776 - val_accuracy: 0.3837\n",
            "Epoch 23/30\n",
            "1302/1302 [==============================] - 186s 142ms/step - loss: 3.4908 - accuracy: 0.4531 - val_loss: 4.0749 - val_accuracy: 0.3840\n",
            "Epoch 24/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.4764 - accuracy: 0.4556 - val_loss: 4.0961 - val_accuracy: 0.3856\n",
            "Epoch 25/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.4615 - accuracy: 0.4583 - val_loss: 4.1138 - val_accuracy: 0.3829\n",
            "Epoch 26/30\n",
            "1302/1302 [==============================] - 189s 145ms/step - loss: 3.4442 - accuracy: 0.4614 - val_loss: 4.1155 - val_accuracy: 0.3804\n",
            "Epoch 27/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.4279 - accuracy: 0.4637 - val_loss: 4.1253 - val_accuracy: 0.3854\n",
            "Epoch 28/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.4141 - accuracy: 0.4664 - val_loss: 4.1134 - val_accuracy: 0.3849\n",
            "Epoch 29/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.3992 - accuracy: 0.4695 - val_loss: 4.1280 - val_accuracy: 0.3840\n",
            "Epoch 30/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 3.3847 - accuracy: 0.4717 - val_loss: 4.1475 - val_accuracy: 0.3844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cae9c4fdc60>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We observe a much poorer performance despite deeper depth on the vanilla Transformer. Let us try to extend the depth more one time....**"
      ],
      "metadata": {
        "id": "rMYLowYXWTSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "sequence_length = 20\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "\n",
        "# Add 3 Encoder Layers\n",
        "for _ in range(9):\n",
        "    x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "encoder_outputs = x  # Output of the final encoder layer\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "\n",
        "# Add 3 Decoder Layers\n",
        "for _ in range(9):\n",
        "    x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs, mask_=None)\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "# Model\n",
        "transformer_3 = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "transformer_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meOmnTvZTvDZ",
        "outputId": "b3b911da-bad3-4123-eb6d-7919d0bd4b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Po  (None, None, 256)            3845120   ['english[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_3 (Tra  (None, None, 256)            3155456   ['positional_embedding_2[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " transformer_encoder_4 (Tra  (None, None, 256)            3155456   ['transformer_encoder_3[0][0]'\n",
            " nsformerEncoder)                                                   ]                             \n",
            "                                                                                                  \n",
            " transformer_encoder_5 (Tra  (None, None, 256)            3155456   ['transformer_encoder_4[0][0]'\n",
            " nsformerEncoder)                                                   ]                             \n",
            "                                                                                                  \n",
            " transformer_encoder_6 (Tra  (None, None, 256)            3155456   ['transformer_encoder_5[0][0]'\n",
            " nsformerEncoder)                                                   ]                             \n",
            "                                                                                                  \n",
            " transformer_encoder_7 (Tra  (None, None, 256)            3155456   ['transformer_encoder_6[0][0]'\n",
            " nsformerEncoder)                                                   ]                             \n",
            "                                                                                                  \n",
            " transformer_encoder_8 (Tra  (None, None, 256)            3155456   ['transformer_encoder_7[0][0]'\n",
            " nsformerEncoder)                                                   ]                             \n",
            "                                                                                                  \n",
            " transformer_encoder_9 (Tra  (None, None, 256)            3155456   ['transformer_encoder_8[0][0]'\n",
            " nsformerEncoder)                                                   ]                             \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " transformer_encoder_10 (Tr  (None, None, 256)            3155456   ['transformer_encoder_9[0][0]'\n",
            " ansformerEncoder)                                                  ]                             \n",
            "                                                                                                  \n",
            " positional_embedding_3 (Po  (None, None, 256)            3845120   ['spanish[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_11 (Tr  (None, None, 256)            3155456   ['transformer_encoder_10[0][0]\n",
            " ansformerEncoder)                                                  ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder_3 (Tra  (None, None, 256)            5259520   ['positional_embedding_3[0][0]\n",
            " nsformerDecoder)                                                   ',                            \n",
            "                                                                     'transformer_encoder_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder_4 (Tra  (None, None, 256)            5259520   ['transformer_decoder_3[0][0]'\n",
            " nsformerDecoder)                                                   , 'transformer_encoder_11[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " transformer_decoder_5 (Tra  (None, None, 256)            5259520   ['transformer_decoder_4[0][0]'\n",
            " nsformerDecoder)                                                   , 'transformer_encoder_11[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " transformer_decoder_6 (Tra  (None, None, 256)            5259520   ['transformer_decoder_5[0][0]'\n",
            " nsformerDecoder)                                                   , 'transformer_encoder_11[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " transformer_decoder_7 (Tra  (None, None, 256)            5259520   ['transformer_decoder_6[0][0]'\n",
            " nsformerDecoder)                                                   , 'transformer_encoder_11[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " transformer_decoder_8 (Tra  (None, None, 256)            5259520   ['transformer_decoder_7[0][0]'\n",
            " nsformerDecoder)                                                   , 'transformer_encoder_11[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " transformer_decoder_9 (Tra  (None, None, 256)            5259520   ['transformer_decoder_8[0][0]'\n",
            " nsformerDecoder)                                                   , 'transformer_encoder_11[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " transformer_decoder_10 (Tr  (None, None, 256)            5259520   ['transformer_decoder_9[0][0]'\n",
            " ansformerDecoder)                                                  , 'transformer_encoder_11[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " transformer_decoder_11 (Tr  (None, None, 256)            5259520   ['transformer_decoder_10[0][0]\n",
            " ansformerDecoder)                                                  ',                            \n",
            "                                                                     'transformer_encoder_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 256)            0         ['transformer_decoder_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_49 (Dense)            (None, None, 15000)          3855000   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 87280024 (332.95 MB)\n",
            "Trainable params: 87280024 (332.95 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tzIhO2QhVExI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = transformer_2.fit(train_ds, epochs=30, validation_data=val_ds)\n",
        "\n",
        "# Visualize Loss Over Epochs\n",
        "#plt.plot(history.history['loss'], label='Training Loss')\n",
        "#plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "#plt.title('Loss Over Epochs')\n",
        "#plt.xlabel('Epochs')\n",
        "#plt.ylabel('Loss')\n",
        "#plt.legend()\n",
        "#plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# Assuming you've already compiled the model and have the training data\n",
        "# ...\n",
        "\n",
        "# Create a figure and axis for the live plot\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title('Dynamic Loss Update')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "\n",
        "# Initialize empty lines for training and validation loss\n",
        "line_train, = ax.plot([], [], label='Training Loss')\n",
        "line_val, = ax.plot([], [], label='Validation Loss')\n",
        "ax.legend()\n",
        "\n",
        "def update(epoch):\n",
        "    # Assuming you have access to the training history\n",
        "    line_train.set_data(range(1, epoch + 1), history.history['loss'][:epoch])\n",
        "    line_val.set_data(range(1, epoch + 1), history.history['val_loss'][:epoch])\n",
        "    return line_train, line_val\n",
        "\n",
        "# Set the number of frames to the number of epochs\n",
        "num_epochs = 10  # Adjust as needed\n",
        "ani = FuncAnimation(fig, update, frames=range(1, num_epochs + 1), blit=True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "YUT7v303Tu6J",
        "outputId": "1267f202-95c7-47bc-ba67-29b2e9b86378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a28c6e86bf21>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Visualize Loss Over Epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.plot(history.history['loss'], label='Training Loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.plot(history.history['val_loss'], label='Validation Loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transformer_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "akD8_EJ9U6eU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}