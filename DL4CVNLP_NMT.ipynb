{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakshith12-pixel/Neural_Machine_Translation/blob/main/DL4CVNLP_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk_vKh4YEfhl"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ms8SJA8jELck"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is the baseline model we will be comparing against**"
      ],
      "metadata": {
        "id": "bhk0GH7It4Vg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XW-WstYmH-4I"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim    # Dimension of embedding. 4 in the dummy example\n",
        "        self.dense_dim = dense_dim    # No. of neurons in dense layer\n",
        "        self.num_heads = num_heads    # No. of heads for MultiHead Attention layer\n",
        "        self.attention = layers.MultiHeadAttention(   # MultiHead Attention layer -\n",
        "            num_heads=num_heads, key_dim=embed_dim)   # see coloured pic above\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]    # encoders are stacked on top of the other.\n",
        "        )                                 # So output dimension is also embed_dim\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    # Call function based on figure above\n",
        "    def call(self, inputs, mask_=None):\n",
        "        if mask_ is not None:\n",
        "            mask = mask[:, tf.newaxis, :]   # Will discuss in next tutorial\n",
        "            print(f\"**test: mask in not None. mask = {mask_}\")\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask_)  # Query: inputs, Value: inputs, Keys: Same as Values by default\n",
        "                                                  # Q: Can you see how this is self attention?\n",
        "        proj_input = self.layernorm_1(inputs + attention_output) # LayerNormalization; + Recall cat picture\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)  # LayerNormalization + Residual connection\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qCAWpi5zGUlx"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        # input_dim = (token) vocabulary size,  output_dim = embedding size\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.token_embeddings = layers.Embedding(       # Q: what is input_dim and output_dim?\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(    # Q: Why input_dim = seq_length?\n",
        "            input_dim=sequence_length, output_dim=output_dim)   # Q: What is the vocab for this Embedding layer\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):   # inputs will be a batch of sequences (batch, seq_len)\n",
        "\n",
        "        length = tf.shape(inputs)[-1]     # lenght will just be sequence length\n",
        "        positions = tf.range(start=0, limit=length, delta=1) # indices for input to positional embedding\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions     # ADD the embeddings\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):  # makes this layer a mask-generating layer\n",
        "        return tf.math.not_equal(inputs, 0)     #mask will get propagated to the next layer.\n",
        "\n",
        "    # When using custom layers, this enables the layer to be reinstantiated from its config dict,\n",
        "    # which is useful during model saving and loading.\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T92X85GUFCLn"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        # Define the layers. Let's point them out in the diagram\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        # Now we have 2 MultiHead Attention layers - one for ___ attention and one for ____ attention\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True #ensures that the layer will propagate its input mask to its outputs;\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1])) # sequence_length == input_shape[1]\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "              tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask_=None): # two inputs: decoder i/p and encoder o/p\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        attention_output_1 = self.attention_1(    # Q: What kind of attention?\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask) # Q: What will the causal_mask do?\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(  # Q: Is this self attention?\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,    # Key and Value coming from encoder hence this is cross attention\n",
        "            key=encoder_outputs,\n",
        "            # attention_mask=padding_mask,\n",
        "        )\n",
        "\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ltu1dmtHoyV",
        "outputId": "605e6711-81b9-4628-92d7-bab56e9ad561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            5125120   ['english[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Po  (None, None, 256)            5125120   ['spanish[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Tra  (None, None, 256)            3155456   ['positional_embedding_1[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_2[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 256)            0         ['transformer_decoder[0][0]'] \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, None, 20000)          5140000   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23805216 (90.81 MB)\n",
            "Trainable params: 23805216 (90.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# English to spanish translation\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "sequence_length = 20\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs) # Q: First arg acts like a ___ for pos embedding layer\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) #Q: What are these arguments?\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs,mask_=None) # Q: What are the call arguments in the picture?\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs) # Note that there are two input layers\n",
        "transformer.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605e6711-81b9-4628-92d7-bab56e9ad561",
        "id": "BP-eYSdKkT2j"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            5125120   ['english[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Po  (None, None, 256)            5125120   ['spanish[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Tra  (None, None, 256)            3155456   ['positional_embedding_1[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_2[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 256)            0         ['transformer_decoder[0][0]'] \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, None, 20000)          5140000   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23805216 (90.81 MB)\n",
            "Trainable params: 23805216 (90.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# English to spanish translation\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "sequence_length = 20\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs) # Q: First arg acts like a ___ for pos embedding layer\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) #Q: What are these arguments?\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs,mask_=None) # Q: What are the call arguments in the picture?\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs) # Note that there are two input layers\n",
        "transformer.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0Y2NmDV7lF6"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr3nOQKCEOCe"
      },
      "source": [
        "Download the data for english to spanish translation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjxZZr-KujpN",
        "outputId": "7e513fd3-d083-4d9b-b81e-8cff9f621d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-23 16:45:34--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.193.207, 172.253.123.207, 142.250.97.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.193.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "\rspa-eng.zip           0%[                    ]       0  --.-KB/s               \rspa-eng.zip         100%[===================>]   2.52M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2023-11-23 16:45:34 (328 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -q spa-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxaC6lh95Ox2",
        "outputId": "0217fdce-ab5d-4ed2-d953-fe5c97a78c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You can't view Flash content on an iPad. However, you can easily email yourself the URLs of these web pages and view that content on your regular computer when you get home.\tNo puedes ver contenido en Flash en un iPad. Sin embargo, puedes fácilmente enviarte por correo electrónico las URL's de esas páginas web y ver el contenido en tu computadora cuando llegas a casa.\n",
            "A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\tUn error que cometen a menudo los jóvenes es el de comenzar a aprender demasiadas lenguas al mismo tiempo, porque subestiman sus dificultades y sobrestiman sus propias capacidades para aprenderlas.\n",
            "No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\tNo importa cuánto insistas en convencer a la gente de que el chocolate es vainilla, seguirá siendo chocolate, aunque puede que te convenzas a ti mismo y a algunos otros de que es vainilla.\n",
            "In 1969, Roger Miller recorded a song called \"You Don't Want My Love.\" Today, this song is better known as \"In the Summer Time.\" It's the first song he wrote and sang that became popular.\tEn 1969, Roger Miller grabó una canción llamada \"Tú no quieres mi amor\". Hoy, esta canción es más conocida como \"En el verano\". Es la primera canción que escribió y cantó que se convirtió popular.\n",
            "A child who is a native speaker usually knows many things about his or her language that a non-native speaker who has been studying for years still does not know and perhaps will never know.\tUn niño que es hablante nativo normalmente sabe muchas cosas acerca de su lengua que un hablante no nativo que lo haya estado estudiando durante muchos años no sabe todavía y que quizá no sabrá nunca.\n",
            "There are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.\tHay cuatro causas principales de muertes relacionadas con el alcohol. Lesión por un accidente automovilístico o violencia es una. Enfermedades como cirrosis del hígado, cáncer, enfermedades del corazón y del sistema circulatorio son las otras.\n",
            "There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college education.\tHay madres y padres que se quedan despiertos después de que sus hijos se hayan dormido y se preguntan cómo conseguir pagar la hipoteca o las facturas del médico, o cómo ahorrar el suficiente dinero para la educación universitaria de sus hijos.\n",
            "A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\tUna huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque están preocupados acerca del cambio climático.\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tComo suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a la siguiente página encontrada por Google y espero encontrar algo menos irritante.\n",
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\tSi quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n"
          ]
        }
      ],
      "source": [
        "!tail spa-eng/spa.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxxtnbv9D2-u",
        "outputId": "9ed13201-d3d6-4de5-e4d2-e9e8d3a91389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"It's the best we have.\", '[start] Es lo mejor que tenemos. [end]')\n",
            "no. of pairs: 118964\n"
          ]
        }
      ],
      "source": [
        "# pre-processing. Separating input and output sequences\n",
        "text_file = \"spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    english, spanish = line.split(\"\\t\")\n",
        "    spanish = \"[start] \" + spanish + \" [end]\" #why isnt same done for english??\n",
        "    text_pairs.append((english, spanish))\n",
        "\n",
        "import random\n",
        "print(random.choice(text_pairs))\n",
        "print(f\"no. of pairs: {len(text_pairs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mcybUiQTD3Az"
      },
      "outputs": [],
      "source": [
        "#splitting data\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pimrC_sEb-I"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj9HjcGE7h4N",
        "outputId": "30e480dc-4699-4634-8de7-cd4d1b87a624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "print(string.punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kBc6EItWD3C3"
      },
      "outputs": [],
      "source": [
        "# Vectorizing the English and Spanish text pairs\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Define which characters to strip out for spanish data- [, ], ¿\n",
        "strip_chars = string.punctuation + \"¿\"  # strip out stadard punctuations + extra one in spanish\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "# strio_chars = !\"#$%&'()*+,-./:;<=>?@\\\\^_`{|}~¿\n",
        "\n",
        "# Custom standardization function for spanish\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(    # Replace elements of input matching regex pattern with rewrite.\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcrueo70ljha"
      },
      "outputs": [],
      "source": [
        "#splitting data\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8pvgWeYljhr"
      },
      "outputs": [],
      "source": [
        "# Vectorizing the English and Spanish text pairs\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Define which characters to strip out for spanish data- [, ], ¿\n",
        "strip_chars = string.punctuation + \"¿\"  # strip out stadard punctuations + extra one in spanish\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "# strio_chars = !\"#$%&'()*+,-./:;<=>?@\\\\^_`{|}~¿\n",
        "\n",
        "# Custom standardization function for spanish\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(    # Replace elements of input matching regex pattern with rewrite.\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvGBDNOmEkMb"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HndSHekBRwZ",
        "outputId": "ddf93d4a-ffdf-449c-efb2-2f66c047a115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original seq\n",
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
            "dec_in\n",
            "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int32)\n",
            "dec_out\n",
            "tf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "seq = tf.range(10)\n",
        "dec_in = seq[:-1]\n",
        "dec_out = seq[1:]\n",
        "\n",
        "print(\"original seq\")\n",
        "print(seq)\n",
        "\n",
        "print(\"dec_in\")\n",
        "print(dec_in)\n",
        "\n",
        "print(\"dec_out\")\n",
        "print(dec_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JMicSLvGD3E_"
      },
      "outputs": [],
      "source": [
        "# Preparing datasets for the translation task\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# returns tuple- ()\n",
        "def format_dataset(eng, spa):\n",
        "    # Q: What are eng and spa pre and post re-assignment\n",
        "    eng = source_vectorization(eng)\n",
        "    spa = target_vectorization(spa)\n",
        "    return ({\n",
        "        \"english\": eng,           # encoder nput\n",
        "        \"spanish\": spa[:, :-1],    # decoder input Q: what is the first axis?\n",
        "    }, spa[:, 1:])                  # decoder ouput\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache() #Use in-memory caching to speed up preprocessing.\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A2wVFs8Epoy",
        "outputId": "e09a315a-e5b9-4172-c641-a5b89f2f390c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['spanish'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n",
            "tf.Tensor(\n",
            "[1033   12   10  687    5  435  145    3    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0], shape=(20,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[ 17   8   2 709   3 224 181   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0], shape=(20,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")\n",
        "    print(targets[3])\n",
        "    print(inputs['english'][3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54BdC0gg7pQS"
      },
      "source": [
        "## Traning and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XjE0Bv-ybZr",
        "outputId": "42a2c6b2-1e1a-475b-e04a-4b6cc6134d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformer\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "fa8C9cTayYDy",
        "outputId": "32b61534-f7c4-438f-d129-bdd2911e1325"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1c49d42d5583>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wd0SMFiZQJz",
        "outputId": "b6cceb8c-8fbd-4546-8964-c9e0ad7bcbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1302/1302 [==============================] - 133s 92ms/step - loss: 4.0376 - accuracy: 0.4115 - val_loss: 2.7648 - val_accuracy: 0.5716\n",
            "Epoch 2/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 2.6468 - accuracy: 0.5960 - val_loss: 2.2234 - val_accuracy: 0.6439\n",
            "Epoch 3/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 2.2522 - accuracy: 0.6494 - val_loss: 2.0483 - val_accuracy: 0.6717\n",
            "Epoch 4/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 2.0551 - accuracy: 0.6773 - val_loss: 1.9875 - val_accuracy: 0.6844\n",
            "Epoch 5/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.9374 - accuracy: 0.6945 - val_loss: 1.9939 - val_accuracy: 0.6859\n",
            "Epoch 6/30\n",
            "1302/1302 [==============================] - 111s 85ms/step - loss: 1.8575 - accuracy: 0.7078 - val_loss: 1.9705 - val_accuracy: 0.6925\n",
            "Epoch 7/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.8041 - accuracy: 0.7176 - val_loss: 1.9876 - val_accuracy: 0.6926\n",
            "Epoch 8/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.7643 - accuracy: 0.7254 - val_loss: 2.0143 - val_accuracy: 0.6948\n",
            "Epoch 9/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.7337 - accuracy: 0.7313 - val_loss: 2.0249 - val_accuracy: 0.6966\n",
            "Epoch 10/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.7068 - accuracy: 0.7372 - val_loss: 2.0250 - val_accuracy: 0.6961\n",
            "Epoch 11/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.6794 - accuracy: 0.7416 - val_loss: 2.0601 - val_accuracy: 0.6972\n",
            "Epoch 12/30\n",
            "1302/1302 [==============================] - 118s 91ms/step - loss: 1.6521 - accuracy: 0.7477 - val_loss: 2.0921 - val_accuracy: 0.6961\n",
            "Epoch 13/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.6318 - accuracy: 0.7514 - val_loss: 2.1017 - val_accuracy: 0.6967\n",
            "Epoch 14/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.6116 - accuracy: 0.7555 - val_loss: 2.1037 - val_accuracy: 0.6973\n",
            "Epoch 15/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5932 - accuracy: 0.7588 - val_loss: 2.1373 - val_accuracy: 0.6951\n",
            "Epoch 16/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5724 - accuracy: 0.7631 - val_loss: 2.1424 - val_accuracy: 0.6964\n",
            "Epoch 17/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5569 - accuracy: 0.7662 - val_loss: 2.1714 - val_accuracy: 0.6975\n",
            "Epoch 18/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5409 - accuracy: 0.7693 - val_loss: 2.2033 - val_accuracy: 0.6940\n",
            "Epoch 19/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.5238 - accuracy: 0.7720 - val_loss: 2.1923 - val_accuracy: 0.6967\n",
            "Epoch 20/30\n",
            "1302/1302 [==============================] - 118s 91ms/step - loss: 1.5107 - accuracy: 0.7749 - val_loss: 2.2656 - val_accuracy: 0.6930\n",
            "Epoch 21/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.4955 - accuracy: 0.7775 - val_loss: 2.2333 - val_accuracy: 0.6944\n",
            "Epoch 22/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4824 - accuracy: 0.7801 - val_loss: 2.2791 - val_accuracy: 0.6946\n",
            "Epoch 23/30\n",
            "1302/1302 [==============================] - 118s 91ms/step - loss: 1.4698 - accuracy: 0.7824 - val_loss: 2.2821 - val_accuracy: 0.6939\n",
            "Epoch 24/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.4590 - accuracy: 0.7846 - val_loss: 2.3207 - val_accuracy: 0.6918\n",
            "Epoch 25/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4503 - accuracy: 0.7862 - val_loss: 2.3206 - val_accuracy: 0.6934\n",
            "Epoch 26/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4361 - accuracy: 0.7888 - val_loss: 2.3620 - val_accuracy: 0.6941\n",
            "Epoch 27/30\n",
            "1302/1302 [==============================] - 118s 91ms/step - loss: 1.4265 - accuracy: 0.7907 - val_loss: 2.3400 - val_accuracy: 0.6960\n",
            "Epoch 28/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4171 - accuracy: 0.7931 - val_loss: 2.3506 - val_accuracy: 0.6941\n",
            "Epoch 29/30\n",
            "1302/1302 [==============================] - 110s 84ms/step - loss: 1.4114 - accuracy: 0.7937 - val_loss: 2.4329 - val_accuracy: 0.6918\n",
            "Epoch 30/30\n",
            "1302/1302 [==============================] - 110s 85ms/step - loss: 1.4006 - accuracy: 0.7958 - val_loss: 2.4055 - val_accuracy: 0.6914\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7df3c36e6020>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]) # other metrics like Bleu....\n",
        "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaPdhwGbwqna",
        "outputId": "bf7d84c7-8453-4fd4-fcf5-baacb91b6071",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Do you like tortellini?\n",
            "[start] te gustan los [UNK] [end]\n",
            "-\n",
            "Our cow doesn't give us any milk.\n",
            "[start] nuestra [UNK] no nos da leche [end]\n",
            "-\n",
            "He had an accident on his way home.\n",
            "[start] Él tuvo un accidente en su camino a casa [end]\n",
            "-\n",
            "Tom didn't want to tell Mary the sad news.\n",
            "[start] tom no quería decirle a maría la triste [end]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(4):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ije_bIxsnGc"
      },
      "source": [
        "Note that both the Trans- formerEncoder and the TransformerDecoder are shape-invariant, so you could be stacking many of them to create a more powerful encoder or decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying different architectures**"
      ],
      "metadata": {
        "id": "VVCgLy_psphZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "fg3ivO12jZ5C"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim    # Dimension of embedding. 4 in the dummy example\n",
        "        self.dense_dim = dense_dim    # No. of neurons in dense layer\n",
        "        self.num_heads = num_heads    # No. of heads for MultiHead Attention layer\n",
        "        self.attention = layers.MultiHeadAttention(   # MultiHead Attention layer -\n",
        "            num_heads=num_heads, key_dim=embed_dim)   # see coloured pic above\n",
        "        self.attention_2 = layers.MultiHeadAttention(   # MultiHead Attention layer -\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_3 = layers.MultiHeadAttention(   # MultiHead Attention layer -\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]    # encoders are stacked on top of the other.\n",
        "        )\n",
        "        self.dense_proj_2 = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]    # encoders are stacked on top of the other.\n",
        "        )\n",
        "        self.dense_proj_3 = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]    # encoders are stacked on top of the other.\n",
        "        )                            # So output dimension is also embed_dim\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "\n",
        "    # Call function based on figure above\n",
        "    def call(self, inputs, mask_=None):\n",
        "        if mask_ is not None:\n",
        "            mask = mask[:, tf.newaxis, :]   # Will discuss in next tutorial\n",
        "            print(f\"**test: mask in not None. mask = {mask_}\")\n",
        "\n",
        "        attention_output = self.attention(\n",
        "        inputs, inputs, attention_mask=mask_)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "        proj_output, proj_output, attention_mask=mask_)\n",
        "        proj_input_2 = self.layernorm_2(proj_output + attention_output_2)\n",
        "        proj_output_2 = self.dense_proj_2(proj_input_2)\n",
        "\n",
        "        attention_output_3 = self.attention_3(\n",
        "        proj_output_2, proj_output_2, attention_mask=mask_)\n",
        "        proj_input_3 = self.layernorm_3(proj_output_2 + attention_output_3)\n",
        "        proj_output_3 = self.dense_proj_3(proj_input_3)\n",
        "\n",
        "        return self.layernorm_3(proj_input_3 + proj_output_3)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        # input_dim = (token) vocabulary size,  output_dim = embedding size\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.token_embeddings = layers.Embedding(       # Q: what is input_dim and output_dim?\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(    # Q: Why input_dim = seq_length?\n",
        "            input_dim=sequence_length, output_dim=output_dim)   # Q: What is the vocab for this Embedding layer\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):   # inputs will be a batch of sequences (batch, seq_len)\n",
        "\n",
        "        length = tf.shape(inputs)[-1]     # lenght will just be sequence length\n",
        "        positions = tf.range(start=0, limit=length, delta=1) # indices for input to positional embedding\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions     # ADD the embeddings\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):  # makes this layer a mask-generating layer\n",
        "        return tf.math.not_equal(inputs, 0)     #mask will get propagated to the next layer.\n",
        "\n",
        "    # When using custom layers, this enables the layer to be reinstantiated from its config dict,\n",
        "    # which is useful during model saving and loading.\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        # Define the layers. Let's point them out in the diagram\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        # Now we have 2 MultiHead Attention layers - one for ___ attention and one for ____ attention\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True #ensures that the layer will propagate its input mask to its outputs;\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1])) # sequence_length == input_shape[1]\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "              tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask_=None): # two inputs: decoder i/p and encoder o/p\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        # padding_mask = tf.ones((inputs.shape[0],inputs.shape[-1],inputs.shape[-1]),dtype=\"int32\")\n",
        "        # print(f\"causal_mask=\\n{causal_mask}\")\n",
        "        # print(f\"*** condtion value {mask_ is not None}\")\n",
        "\n",
        "        # if mask_ is not None:\n",
        "        #   print(f\"*** condtion value {mask_ is not None}\")\n",
        "        #   print(f\"*** test: mask = \\n{mask_}\")\n",
        "        #   padding_mask = tf.cast(\n",
        "        #       mask_[:, tf.newaxis, :], dtype=\"int32\")\n",
        "        #   padding_mask = tf.minimum(padding_mask, causal_mask) # union of 0s\n",
        "        #   print(f\"**** test padding mask: \\n{padding_mask}\")\n",
        "        attention_output_1 = self.attention_1(    # Q: What kind of attention?\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask) # Q: What will the causal_mask do?\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(  # Q: Is this self attention?\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,    # Key and Value coming from encoder hence this is cross attention\n",
        "            key=encoder_outputs,\n",
        "            # attention_mask=padding_mask,\n",
        "        )\n",
        "\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -q spa-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycQbAZC2vHVk",
        "outputId": "c4fa0318-f4ce-4426-96af-9d1064f5fac6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-23 18:42:02--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.207, 173.194.217.207, 173.194.218.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip.1’\n",
            "\n",
            "\rspa-eng.zip.1         0%[                    ]       0  --.-KB/s               \rspa-eng.zip.1       100%[===================>]   2.52M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-11-23 18:42:02 (209 MB/s) - ‘spa-eng.zip.1’ saved [2638744/2638744]\n",
            "\n",
            "replace spa-eng/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace spa-eng/spa.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = \"spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    english, spanish = line.split(\"\\t\")\n",
        "    spanish = \"[start] \" + spanish + \" [end]\" #why isnt same done for english??\n",
        "    text_pairs.append((english, spanish))\n",
        "\n",
        "import random\n",
        "print(random.choice(text_pairs))\n",
        "print(f\"no. of pairs: {len(text_pairs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckgyPX8rvPJ7",
        "outputId": "4daf4385-2ac0-46be-c5f2-d697ac403d10"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('That would be a problem.', '[start] Eso sería un problema. [end]')\n",
            "no. of pairs: 118964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# English to spanish translation\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "sequence_length = 20\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs) # Q: First arg acts like a ___ for pos embedding layer\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) #Q: What are these arguments?\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs,mask_=None) # Q: What are the call arguments in the picture?\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer_2 = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs) # Note that there are two input layers\n",
        "transformer_2.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvQpJy6DkdLK",
        "outputId": "9ef88b36-8da7-405d-ca3d-ded6e76274df"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_9 (Po  (None, None, 256)            3845120   ['english[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " positional_embedding_10 (P  (None, None, 256)            3845120   ['spanish[0][0]']             \n",
            " ositionalEmbedding)                                                                              \n",
            "                                                                                                  \n",
            " transformer_encoder_5 (Tra  (None, None, 256)            9464832   ['positional_embedding_9[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder_4 (Tra  (None, None, 256)            5259520   ['positional_embedding_10[0][0\n",
            " nsformerDecoder)                                                   ]',                           \n",
            "                                                                     'transformer_encoder_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, None, 256)            0         ['transformer_decoder_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_43 (Dense)            (None, None, 15000)          3855000   ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 26269592 (100.21 MB)\n",
            "Trainable params: 26269592 (100.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jRVQQdt7lmqu"
      },
      "outputs": [],
      "source": [
        "#splitting data\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HUfhrNh5lmqv"
      },
      "outputs": [],
      "source": [
        "# Vectorizing the English and Spanish text pairs\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Define which characters to strip out for spanish data- [, ], ¿\n",
        "strip_chars = string.punctuation + \"¿\"  # strip out stadard punctuations + extra one in spanish\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "# strio_chars = !\"#$%&'()*+,-./:;<=>?@\\\\^_`{|}~¿\n",
        "\n",
        "# Custom standardization function for spanish\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(    # Replace elements of input matching regex pattern with rewrite.\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# returns tuple- ()\n",
        "def format_dataset(eng, spa):\n",
        "    # Q: What are eng and spa pre and post re-assignment\n",
        "    eng = source_vectorization(eng)\n",
        "    spa = target_vectorization(spa)\n",
        "    return ({\n",
        "        \"english\": eng,           # encoder nput\n",
        "        \"spanish\": spa[:, :-1],    # decoder input Q: what is the first axis?\n",
        "    }, spa[:, 1:])                  # decoder ouput\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache() #Use in-memory caching to speed up preprocessing.\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "yvlzehR-lyif"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_2.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\",\"Bleu\"]) # other metrics like Bleu....\n"
      ],
      "metadata": {
        "id": "cRjz7JulrPDD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_2.fit(train_ds, epochs=30, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "7cHylpVnrUqu",
        "outputId": "2b49a035-65e7-4f64-e07b-4ad7c338b889"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ebf877622e8c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1131, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1225, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 723, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n\n    TypeError: 'str' object is not callable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_3 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.dense_proj_2 = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.dense_proj_3 = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask_=None):\n",
        "        if mask_ is not None:\n",
        "            mask = mask_[:, tf.newaxis, :]\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask_)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            proj_output, proj_output, attention_mask=mask_)\n",
        "        proj_input_2 = self.layernorm_2(proj_output + attention_output_2)\n",
        "        proj_output_2 = self.dense_proj_2(proj_input_2)\n",
        "\n",
        "        attention_output_3 = self.attention_3(\n",
        "            proj_output_2, proj_output_2, attention_mask=mask_)\n",
        "        proj_input_3 = self.layernorm_3(proj_output_2 + attention_output_3)\n",
        "        proj_output_3 = self.dense_proj_3(proj_input_3)\n",
        "\n",
        "        return self.layernorm_3(proj_input_3 + proj_output_3)\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask_=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)\n",
        "\n",
        "# Parameters\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "sequence_length = 20\n",
        "vocab_size = 10000  # Replace with your actual vocabulary size\n",
        "\n",
        "# Model inputs\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "\n",
        "# Model architecture\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs, mask_=None)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "# Model creation\n",
        "transformer_model_3 = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "transformer_model_3.summary()\n",
        "\n",
        "# Model compilation\n",
        "transformer_model_3.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\",\"Bleu\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J7BHxbxri3p",
        "outputId": "96cb4be7-9064-4b24-da80-85c5431f541d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_13 (P  (None, None, 256)            2565120   ['english[0][0]']             \n",
            " ositionalEmbedding)                                                                              \n",
            "                                                                                                  \n",
            " positional_embedding_14 (P  (None, None, 256)            2565120   ['spanish[0][0]']             \n",
            " ositionalEmbedding)                                                                              \n",
            "                                                                                                  \n",
            " transformer_encoder_7 (Tra  (None, None, 256)            9464832   ['positional_embedding_13[0][0\n",
            " nsformerEncoder)                                                   ]']                           \n",
            "                                                                                                  \n",
            " transformer_decoder_6 (Tra  (None, None, 256)            5259520   ['positional_embedding_14[0][0\n",
            " nsformerDecoder)                                                   ]',                           \n",
            "                                                                     'transformer_encoder_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, None, 256)            0         ['transformer_decoder_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_61 (Dense)            (None, None, 10000)          2570000   ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22424592 (85.54 MB)\n",
            "Trainable params: 22424592 (85.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model_3.fit(train_ds, epochs=30, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "p3NuWMZJymHK",
        "outputId": "cf41d13e-c72a-4650-f6f5-360531667f89"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-89563b02b99a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer_model_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 20) and (None, 20, 10000) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSI_16S9y5h4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}